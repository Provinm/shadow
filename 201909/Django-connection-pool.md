Gerena Web Team Django 连接池的调研-测试-上线-优化方向
===========

### 背景

由于 Django 框架的 orm 部分没有官方的连接池实现，看文档 [databases](https://docs.djangoproject.com/en/2.2/ref/databases/) 中的持久化部分，是有一个参数 `CONN_MAX_AGE` 来做持久化连接的功能，但是在我们的项目中并不会因为设置了这个参数而取得减少连接数的效果，原因未知。

Web 组这边屡次活动中均存在过多连接数的情况，peak hour 时最多能到 8k 。给 DB 造成了巨大的压力，在 Gcloud 上出现过 mysql 宕机造成服务不可用的事故。


所以，这个问题被提上了日程。

### 调研

在 Google 或者 Github 中搜索关键字 `django connection pool` 会出来很多结果

- [github results](https://github.com/search?q=django+connection+pool)

最后选择了 [django-mysql-geventpool](https://github.com/shunsukeaihara/django-mysql-geventpool), 原因如下：

- 我们的项目采用了 Gevent+Gunicorn 的部署方式，和该库的实现匹配
- 该库没有其他的依赖，在实现上使用了简单的 Queue，而很多其他库借助了 Sqlalchemy 库实现的 pool。

读了该库的源代码，认为其实现满足我们组现在的需求。所以决定拿过来试试看


### 测试

调研好了之后就开始进行测试，当时是用在 `Anniversary` 项目上，安装的是 0.2.4 版本，这个版本仅有  `MAX_CONNS` 参数，在测试中表现良好，达到了连接池的目的，功能上没有问题，但是在测试中存在一些问题

- 使用这个库之后，切记需要把原有的 `CONN_MAX_AGE` 参数去掉，否则会有问题
- `MAX_CONNS` 参数默认每个进程 4 个连接，在压测时不管我怎么调整这个参数的值，其最后的表现都是每个进程 4 个连接，设置的参数并没有生效
- 在 0.2.4 版本中，连接一旦建立，只要连接能够使用，便不会被销毁，这个设计可能存在一些问题，但我不是专业的DBA，不清楚会影响到 DB 的哪一部分。


总的来说，这个库在 0.2.4 版本是有一些小瑕疵的，不过瑕不掩瑜，控制连接池功能上表现的不错。

PS: 在写这个文章是，在 PYPI 上看了一下，0.2.5版本已经 release 了，在下个项目中会继续使用 0.2.5 版本

### 上线

`Anniversary` 上线之后，密切关注了运行的情况，整个运行过程还算顺利

1. 连接池运行良好，连接数控制得很好
2. 在运行过程中没有出现过 error


DB 方面出现了几个问题：


1. 出现了少量的大于 0.1s 的slow query
2. 在项目末期，DB 的内存被塞满了，最后通过重启 DB, 然后下调 buffer size 解决的

这两个问题不确定是否跟使用了 `django-mysql-geventpool` 相关，也可能就是因为业务量太大了导致 mysql 负载过高引起的，还需要找 DBA 分析一下。


### 优化方向

目前看来，我们组在未来一年之内肯定会大量使用 Django 框架，那么会大量使用到这个库，目前仅仅经历了一个项目，可能还有些问题没有暴露出来，这部分未知的问题继续等待发现和解决。

在已知的问题中，需要找时间去探索的是：

- [ ] 配置不生效的原因以及解决方案
- [ ] 0.2.4 版本中管理连接的策略是否会导致 mysql 内存暴涨，需要验证
- [ ] 0.2.5 增加了 `MAX_LIFETIME` 参数，需要继续测试验证

提出的问题慢慢验证解决吧, 该 wiki 会继续更新。直到上述问题解决。

ps 希望能为该库提几个 PR 吧。
